[details]
Data. We focused on synthetic data. This is because most evaluation metrics for speech enhancement performance, including the scale-invariant SNR (SI-SNR), require parallel data, which can only be synthesised. We will conduct an evaluation on real data w.r.t. the ASR accuracy or a non-intrusive metric, such as DNSMOS, in future work. We prepared a speech enhancement dataset using speech from TIMIT and noise from DEMAND. We used the training set of TIMIT to create our training and validation sets and the test set of TIMIT to create our test set. We used noise recordings from DEMAND in the following environments, which we found contained little speech: DKITCHEN, DLIVING, DWASHING, NFIELD, NRIVER, OHALLWAY, OOFFICE, STRAFFIC, and TCAR. Each noise recording was divided into halves, one for the training and the validation sets and the other for the test set. The training set for PULSE consisted of 4019 noisy speech clips and 4019 noise clips $(3.49 \mathrm{~h}$ each). Throughout this experiment, all clips were $3.125 \mathrm{~s}$ long and sampled at $16 \mathrm{kHz}$. The training set for supervised learning consisted of 4019 noisy speech clips along with the corresponding clean speech clips. The training set for MixIT consisted of 4019 noisy speech clips, 4019 noise clips, and the corresponding 4019 mixture (i.e., noisy speech plus noise) clips. In all methods, the validation/test set consisted of $601 / 1680$ noisy speech clips $(0.52 \mathrm{~h} / 1.46 \mathrm{~h})$ along with the corresponding clean speech clips. Each noise clip above was a random excerpt from DEMAND; Each noisy speech clip was generated by adding a TIMIT clip and a random excerpt from DEMAND at an SNR sampled uniformly from the interval $[-5,10] \mathrm{dB}$.